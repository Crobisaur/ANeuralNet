function [Y,Xf,Af] = myNeuralNetworkFunction(X,~,~)
%MYNEURALNETWORKFUNCTION neural network simulation function.
%
% Generated by Neural Network Toolbox function genFunction, 17-Feb-2016 22:38:36.
%
% [Y] = myNeuralNetworkFunction(X,~,~) takes these arguments:
%
%   X = 1xTS cell, 1 inputs over TS timesteps
%   Each X{1,ts} = 4xQ matrix, input #1 at timestep ts.
%
% and returns:
%   Y = 1xTS cell of 1 outputs over TS timesteps.
%   Each Y{1,ts} = 3xQ matrix, output #1 at timestep ts.
%
% where Q is number of samples (or series) and TS is the number of timesteps.

%#ok<*RPMT0>

% ===== NEURAL NETWORK CONSTANTS =====

% Input 1
x1_step1_xoffset = [4.3;2;1;0.1];
x1_step1_gain = [0.555555555555555;0.833333333333333;0.338983050847458;0.833333333333333];
x1_step1_ymin = -1;

% Layer 1
b1 = [-2.157972865425426;-1.5306844982471381;-1.5573946238438687;0.51681766840309906;0.51205483294894416;-1.1534257192904258;1.041873985205793;-1.6967081040927061;-1.9798554558847459;-2.5045139937195349];
IW1_1 = [0.78812717074598115 2.1173392161646554 1.6571883444562081 -0.04616149228614333;0.091412392685380123 -0.39415387142711228 2.6051055941804711 2.0144890482122109;1.297881209516389 -0.15842876212250859 0.81624545122711933 -1.7713553535840283;0.55056972460584119 -0.44817587198048398 -1.7760637579699143 -1.7125042172829692;-1.0126435084388985 -1.7214210943466508 0.84891106564846353 -0.9874119947980361;-1.9669951358050821 1.8005526895539881 -0.5677944463644532 -1.439826697713527;1.0812443167087309 -1.532119068290859 1.517698980557767 1.0841932883829597;-1.2530334441264988 -1.046713488635715 2.6254904158681796 2.4036644964583935;0.04530133591287059 0.042758894339877875 1.58586612272937 -1.9044141816898432;-1.5208613948654237 -1.900222806121463 -0.16063679361693833 -0.41118508225109124];

% Layer 2
b2 = [-0.48781092650847152;-0.64901024569168786;0.7472756699639006];
LW2_1 = [-0.1235647963174452 -0.25278977713342365 -1.0759844634897779 0.73217941796509411 0.2085347176465556 2.5009224176925078 -2.3496793690845985 0.2035973724369296 -0.46954173228523055 0.17843507665630343;-0.5931319711479488 -1.9901863141221621 0.71892184618159172 -0.17526381167901731 0.1042725977280792 -1.8461299496838515 1.0527609923918722 -1.6664183983018768 0.22623739438730597 0.3561087614795706;0.91776714629097589 1.9461933100566644 -0.30949886283215533 -2.2034266312317259 0.24881571699438215 -0.23305820193995286 0.77657026193714318 3.1498881359918531 0.5810894502927606 0.27297595911563061];

% ===== SIMULATION ========

% Format Input Arguments
isCellX = iscell(X);
if ~isCellX, X = {X}; end;

% Dimensions
TS = size(X,2); % timesteps
if ~isempty(X)
    Q = size(X{1},2); % samples/series
else
    Q = 0;
end

% Allocate Outputs
Y = cell(1,TS);

% Time loop
for ts=1:TS
    
    % Input 1
    Xp1 = mapminmax_apply(X{1,ts},x1_step1_gain,x1_step1_xoffset,x1_step1_ymin);
    
    % Layer 1
    a1 = tansig_apply(repmat(b1,1,Q) + IW1_1*Xp1);
    
    % Layer 2
    a2 = softmax_apply(repmat(b2,1,Q) + LW2_1*a1);
    
    % Output 1
    Y{1,ts} = a2;
end

% Final Delay States
Xf = cell(1,0);
Af = cell(2,0);

% Format Output Arguments
if ~isCellX, Y = cell2mat(Y); end
end

% ===== MODULE FUNCTIONS ========

% Map Minimum and Maximum Input Processing Function
function y = mapminmax_apply(x,settings_gain,settings_xoffset,settings_ymin)
y = bsxfun(@minus,x,settings_xoffset);
y = bsxfun(@times,y,settings_gain);
y = bsxfun(@plus,y,settings_ymin);
end

% Competitive Soft Transfer Function
function a = softmax_apply(n)
nmax = max(n,[],1);
n = bsxfun(@minus,n,nmax);
numer = exp(n);
denom = sum(numer,1);
denom(denom == 0) = 1;
a = bsxfun(@rdivide,numer,denom);
end

% Sigmoid Symmetric Transfer Function
function a = tansig_apply(n)
a = 2 ./ (1 + exp(-2*n)) - 1;
end
